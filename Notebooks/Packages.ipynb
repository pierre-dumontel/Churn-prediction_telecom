{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmJXtzsi7SC0Tj3N4pl09a"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "ODN5tpQmONvh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dG4BIuJOEwl"
      },
      "outputs": [],
      "source": [
        "!pip install pandas-profiling -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "JCOa2NU0OIUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "sc = pyspark.SparkContext()\n",
        "sql_sc = pyspark.SQLContext(sc)\n",
        "\n",
        "spark = (pyspark.sql.SparkSession\n",
        "         .builder\n",
        "         .appName('Churn')\n",
        "         .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "jP0Sirm9OtFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType, DateType, FloatType\n",
        "from pyspark.sql.functions import current_timestamp, lit, col, to_timestamp, concat, count, countDistinct, desc, rank, asc, when\n",
        "from pyspark.sql.functions import sum, mean, round, stddev, max, min\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "GfR-1u3MOvBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler  \n",
        "from pyspark.ml.feature import Imputer \n",
        "from pyspark.ml.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "bbZep2uXmFPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_profiling as pdp \n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "81ozC9nDOxH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.combine import SMOTEENN"
      ],
      "metadata": {
        "id": "G9WUcmV0brJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "import graphviz"
      ],
      "metadata": {
        "id": "PRxE0Ap20xym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}